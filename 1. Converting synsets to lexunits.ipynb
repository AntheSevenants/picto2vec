{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "494d9158-2503-47b4-b6bb-929fc1f71fc5",
   "metadata": {},
   "source": [
    "# 1. Converting synsets to lexunits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a4f19e-eda0-4d6a-872a-e5343b35557c",
   "metadata": {},
   "source": [
    "All pictographs are linked to a synset from the Cornetto database. However, later on, we will have to get examples from DutchSemCor, which works on the level of lexunits. Therefore, we will convert all synset ids to lexunit ids in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00bf4f3f-e643-4829-b2cb-d2b40ea0d974",
   "metadata": {},
   "source": [
    "## Loading the lexunit-synset bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bb1ab5-9dd1-4c76-af45-4421603d292c",
   "metadata": {},
   "source": [
    "First, we load in the lexunit-synset bridge. This will allow us to convert from synsets to lexunits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cc8acbd-5fcb-4b75-b3f9-6d49e3a73ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from picto2vec.lexsynbridge import LexSynBridge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b88e9c6-6918-4777-8f1a-309bf18098ce",
   "metadata": {},
   "source": [
    "Then, we load in our conversion dataset. It might take a while to load in, since it internally converts this dataset to a Python `dict` for faster conversion. After loading, we test the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d08e5bd9-68a1-4bfe-ae7b-6a950e18f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lexsynbridge = LexSynBridge(\"data/lex2syn_original.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23921c5e-9dd0-4b44-8073-9504a9565eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r_n-15326,r_n-41758'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexsynbridge.syn2lex(\"d_n-39469\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7c5249-8da9-499f-b5aa-dc84a1b23798",
   "metadata": {},
   "source": [
    "## Converting synsets to lexunits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a1fc8f-931f-49b6-9d13-b28326fb15bf",
   "metadata": {},
   "source": [
    "That works! Now, let's load in our pictograph dataset and convert all columns with synsets in them to lexunits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66acc115-5519-4f51-a3df-6b03f08e0c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba5217df-13a2-4b31-8e56-3319a50b7b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>synset</th>\n",
       "      <th>relation</th>\n",
       "      <th>head</th>\n",
       "      <th>headrel</th>\n",
       "      <th>dependent</th>\n",
       "      <th>deprel</th>\n",
       "      <th>antonym</th>\n",
       "      <th>number</th>\n",
       "      <th>lemma_english</th>\n",
       "      <th>able</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>verdrietig</td>\n",
       "      <td>d_n-31553</td>\n",
       "      <td>synonym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unfortunate,-depressed,-unlucky</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ruzie-maken</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d_v-9067</td>\n",
       "      <td>synonym</td>\n",
       "      <td>d_n-30590</td>\n",
       "      <td>synonym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>argue</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>school</td>\n",
       "      <td>d_n-36313</td>\n",
       "      <td>synonym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>school-rood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>school</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slecht-2</td>\n",
       "      <td>c_578</td>\n",
       "      <td>synonym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bad-/-not-ok</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gebaar-veel</td>\n",
       "      <td>n_a-512478</td>\n",
       "      <td>synonym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gesture-a-lot</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lemma      synset relation      head  headrel  dependent   deprel  \\\n",
       "0   verdrietig   d_n-31553  synonym       NaN      NaN        NaN      NaN   \n",
       "1  ruzie-maken         NaN      NaN  d_v-9067  synonym  d_n-30590  synonym   \n",
       "2       school   d_n-36313  synonym       NaN      NaN        NaN      NaN   \n",
       "3     slecht-2       c_578  synonym       NaN      NaN        NaN      NaN   \n",
       "4  gebaar-veel  n_a-512478  synonym       NaN      NaN        NaN      NaN   \n",
       "\n",
       "       antonym  number                    lemma_english able  \n",
       "0          NaN     NaN  unfortunate,-depressed,-unlucky  NaN  \n",
       "1          NaN     NaN                            argue  NaN  \n",
       "2  school-rood     NaN                           school  NaN  \n",
       "3          NaN     NaN                     bad-/-not-ok  NaN  \n",
       "4          NaN     NaN                    gesture-a-lot  NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sense_df = pd.read_csv(\"data/sclera.csv\", names=[ \"lemma\", \"synset\", \"relation\", \"head\", \"headrel\", \"dependent\", \"deprel\", \"antonym\", \"number\", \"lemma_english\", \"able\" ])\n",
    "sense_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df4ed076-cd32-44b9-943e-6a6e5bd40519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d_v-293911 to lexunit failed!\n",
      "r_n-24688 to lexunit failed!\n",
      "r_n-5918 to lexunit failed!\n",
      "c_545200 to lexunit failed!\n",
      "r_n-23331 to lexunit failed!\n",
      "r_n-10194 to lexunit failed!\n",
      "r_a-10906 to lexunit failed!\n",
      "d_n-323738 to lexunit failed!\n",
      "d_a9366 to lexunit failed!\n",
      "d_n40023 to lexunit failed!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lemma</th>\n",
       "      <th>synset</th>\n",
       "      <th>relation</th>\n",
       "      <th>head</th>\n",
       "      <th>headrel</th>\n",
       "      <th>dependent</th>\n",
       "      <th>deprel</th>\n",
       "      <th>antonym</th>\n",
       "      <th>number</th>\n",
       "      <th>lemma_english</th>\n",
       "      <th>able</th>\n",
       "      <th>lexunit</th>\n",
       "      <th>head_lexunit</th>\n",
       "      <th>dependent_lexunit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>verdrietig</td>\n",
       "      <td>d_n-31553</td>\n",
       "      <td>synonym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>unfortunate,-depressed,-unlucky</td>\n",
       "      <td>NaN</td>\n",
       "      <td>r_n-39979,d_n-40708,r_n-11597,r_n-11598,r_n-20...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ruzie-maken</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d_v-9067</td>\n",
       "      <td>synonym</td>\n",
       "      <td>d_n-30590</td>\n",
       "      <td>synonym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>argue</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>c_546110</td>\n",
       "      <td>r_n-32330,r_n-8012,r_n-11053,r_n-16733,d_n-525...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>school</td>\n",
       "      <td>d_n-36313</td>\n",
       "      <td>synonym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>school-rood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>school</td>\n",
       "      <td>NaN</td>\n",
       "      <td>r_n-33120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slecht-2</td>\n",
       "      <td>c_578</td>\n",
       "      <td>synonym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bad-/-not-ok</td>\n",
       "      <td>NaN</td>\n",
       "      <td>d_a-208278,r_a-15054,r_a-10080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gebaar-veel</td>\n",
       "      <td>n_a-512478</td>\n",
       "      <td>synonym</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gesture-a-lot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>r_a-11649,r_a-15342,c_545575,r_a-16466,r_a-104...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lemma      synset relation      head  headrel  dependent   deprel  \\\n",
       "0   verdrietig   d_n-31553  synonym       NaN      NaN        NaN      NaN   \n",
       "1  ruzie-maken         NaN      NaN  d_v-9067  synonym  d_n-30590  synonym   \n",
       "2       school   d_n-36313  synonym       NaN      NaN        NaN      NaN   \n",
       "3     slecht-2       c_578  synonym       NaN      NaN        NaN      NaN   \n",
       "4  gebaar-veel  n_a-512478  synonym       NaN      NaN        NaN      NaN   \n",
       "\n",
       "       antonym  number                    lemma_english able  \\\n",
       "0          NaN     NaN  unfortunate,-depressed,-unlucky  NaN   \n",
       "1          NaN     NaN                            argue  NaN   \n",
       "2  school-rood     NaN                           school  NaN   \n",
       "3          NaN     NaN                     bad-/-not-ok  NaN   \n",
       "4          NaN     NaN                    gesture-a-lot  NaN   \n",
       "\n",
       "                                             lexunit head_lexunit  \\\n",
       "0  r_n-39979,d_n-40708,r_n-11597,r_n-11598,r_n-20...          NaN   \n",
       "1                                                NaN     c_546110   \n",
       "2                                          r_n-33120          NaN   \n",
       "3                     d_a-208278,r_a-15054,r_a-10080          NaN   \n",
       "4  r_a-11649,r_a-15342,c_545575,r_a-16466,r_a-104...          NaN   \n",
       "\n",
       "                                   dependent_lexunit  \n",
       "0                                                NaN  \n",
       "1  r_n-32330,r_n-8012,r_n-11053,r_n-16733,d_n-525...  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sense_df['lexunit'] = sense_df.apply(lambda row: lexsynbridge.syn2lex(row[\"synset\"]), axis=1)\n",
    "sense_df['head_lexunit'] = sense_df.apply(lambda row: \",\".join(list(filter(lambda lexunit: lexunit != False, list(map(lambda synset: lexsynbridge.syn2lex(synset), row[\"head\"].split(\",\")))))) if type(row[\"head\"]) == str else np.nan, axis=1)\n",
    "sense_df['dependent_lexunit'] = sense_df.apply(lambda row: \",\".join(list(filter(lambda lexunit: lexunit !=False, list(map(lambda synset: lexsynbridge.syn2lex(synset), row[\"dependent\"].split(\",\")))))) if type(row[\"dependent\"]) == str else np.nan, axis=1)\n",
    "sense_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730b6b2f-797e-43da-ac68-059837cb7dee",
   "metadata": {},
   "source": [
    "Some conversions will have failed. I don't know why this is the case, but it's not something I can fix, since I've noticed that most of the databases for Dutch are a bit... messy. We hope that this won't pose issues later on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd63abbe-6be5-4aea-9aa3-f832c4a9d672",
   "metadata": {},
   "source": [
    "## Exporting the new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9b4fb5-35fc-4ad6-b833-b0074815df61",
   "metadata": {},
   "source": [
    "We export the new dataset as JSON. This will be helpful later on, since pandas can be kinda slow when indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "daa9ef17-6b4b-43b4-86c5-73b4990ed902",
   "metadata": {},
   "outputs": [],
   "source": [
    "sense_df.to_json(\"test_senses.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243f43a8-ae98-4590-b871-1b4cfb58aa88",
   "metadata": {},
   "source": [
    "That's it for this notebook!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
